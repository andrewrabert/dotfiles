#!/usr/bin/env python3
import argparse
import hashlib
import json
import pathlib
import subprocess
import tempfile
import zlib

import tqdm


def all_files(root):
    stack = [pathlib.Path(root)]
    files = []
    while stack:
        for path in stack.pop().iterdir():
            if path.is_file():
                files.append(path)
            elif path.is_dir():
                stack.append(path)
    return files


def multi_hash(path):
    checksum_crc32 = 0
    hasher_md5 = hashlib.md5()
    hasher_sha1 = hashlib.sha1()
    hasher_sha256 = hashlib.sha256()
    with open(path, 'rb') as handle:
        while data := handle.read(65536):
            checksum_crc32 = zlib.crc32(data, checksum_crc32)
            hasher_md5.update(data)
            hasher_sha1.update(data)
            hasher_sha256.update(data)
    return {
        'crc32': hex(checksum_crc32)[2:],
        'md5': hasher_md5.hexdigest(),
        'sha1': hasher_sha1.hexdigest(),
        'sha256': hasher_sha256.hexdigest(),
    }


def safe_write(path, data):
    path = pathlib.Path(path)
    if isinstance(data, str):
        data = data.encode()
    with tempfile.NamedTemporaryFile(delete=False, dir=path.parent) as handle:
        temp_path = pathlib.Path(handle.name)
        try:
            temp_path.write_bytes(data)
            temp_path.rename(path)
        finally:
            try:
                temp_path.unlink()
            except FileNotFoundError:
                pass


def extract(source, target):
    subprocess.run(
        ['extract',
         '--quiet',
         '-p', target,
         '--',
         source],
        check=True)


def file_hash_recorder(path):
    proc = subprocess.run(
        ['file-hash-recorder',
         '--no-progress',
         '--archive-contents',
         '--',
         path],
        stdout=subprocess.PIPE,
        check=True)
    return json.loads(proc.stdout.decode())


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--no-progress', action='store_true')
    parser.add_argument('-f', '--force', action='store_true')
    parser.add_argument('-o', '--output', type=pathlib.Path)
    parser.add_argument('--archive-contents', action='store_true')
    parser.add_argument('path', type=pathlib.Path)
    args = parser.parse_args()

    results = {}
    ignore_paths = set()
    output_path = None
    if args.output is not None:
        output_path = args.output
        ignore_paths.add(output_path)
        if output_path.exists():
            results = json.loads(output_path.read_text())

    found = set()

    pending_paths = []
    for path in all_files(args.path):
        if path in ignore_paths:
            continue
        name = str(path.relative_to(args.path))
        found.add(name)
        stat = path.stat()
        if name in results \
                and results[name]['mtime'] == stat.st_mtime \
                and results[name]['size'] == stat.st_size \
                and not args.force:
            continue
        pending_paths.append((path, name, stat))

    if not args.no_progress:
        pending_paths = tqdm.tqdm(pending_paths)

    for path, name, stat in pending_paths:
        hashes = multi_hash(path)
        data = {
            'mtime': stat.st_mtime,
            'size': stat.st_size,
            'sha1': hashes['sha1'],
            'sha256':  hashes['sha256'],
            'md5':  hashes['md5'],
            'crc32':  hashes['crc32'],
        }
        if args.archive_contents and path.name.endswith('.tar.zst'):
            with tempfile.TemporaryDirectory() as tmp:
                extract(path, tmp)
                data['archive_contents'] = file_hash_recorder(tmp)
        results[name] = data
        if output_path:
            safe_write(
                output_path,
                json.dumps(results, indent=2, sort_keys=True),
            )

    modified = False
    for name in list(results):
        if name not in found:
            results.pop(name)
            modified = True
    if output_path:
        if modified:
            safe_write(
                output_path,
                json.dumps(results, indent=2, sort_keys=True),
            )
    else:
        print(json.dumps(results, indent=2, sort_keys=True))


if __name__ == '__main__':
    main()
